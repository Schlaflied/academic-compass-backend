# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# â€œå­¦æœ¯ç½—ç›˜â€åç«¯æ ¸å¿ƒåº”ç”¨ (Academic Compass Backend Core)
# ç‰ˆæœ¬: 3.0 - Project Lens åŒæ­¥å‡çº§ç‰ˆ
# æè¿°: é›†æˆäº†åŸºäºIPçš„æ¯æ—¥è¯·æ±‚é™æµåŠŸèƒ½ï¼Œå¹¶é‡æ„äº†AIåˆ†æé€»è¾‘ï¼Œ
#       ä½¿å…¶èƒ½å¤Ÿç”Ÿæˆå¸¦æœ‰å¼•ç”¨æ¥æºçš„æŠ¥å‘Šï¼Œé£æ ¼ä¸Project Lensä¿æŒä¸€è‡´ã€‚
# -----------------------------------------------------------------------------

import os
import requests
import google.generativeai as genai
import time
import re
from flask import Flask, request, jsonify
from flask_cors import CORS
# --- æ–°å¢ï¼šå¯¼å…¥é™æµåº“ ---
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

# --- 1. åˆå§‹åŒ–å’Œé…ç½® ---
app = Flask(__name__)
CORS(app)

# --- æ–°å¢ï¼šåˆå§‹åŒ–é™æµå™¨ ---
# ä½¿ç”¨ get_remote_address æ¥æ ¹æ®ç”¨æˆ·çš„IPåœ°å€è¿›è¡Œé™æµ
limiter = Limiter(
    get_remote_address,
    app=app,
    default_limits=["200 per day", "50 per hour"], # è®¾ç½®é»˜è®¤çš„å…¨å±€é™æµ
    storage_uri="memory://" # ä½¿ç”¨å†…å­˜å­˜å‚¨
)

# --- 2. APIå¯†é’¥é…ç½® (æ— å˜åŒ–) ---
try:
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    SEARCH_API_KEY = os.getenv("SEARCH_API_KEY")
    SEARCH_ENGINE_ID = os.getenv("SEARCH_ENGINE_ID")
    if not all([GEMINI_API_KEY, SEARCH_API_KEY, SEARCH_ENGINE_ID]):
        raise ValueError("ä¸€ä¸ªæˆ–å¤šä¸ªAPIå¯†é’¥/ç¯å¢ƒå˜é‡ç¼ºå¤±ã€‚")
    genai.configure(api_key=GEMINI_API_KEY)
    print("âœ… æ‰€æœ‰APIå¯†é’¥é…ç½®æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ APIå¯†é’¥é…ç½®å¤±è´¥: {e}")

# --- 3. è¾…åŠ©å‡½æ•°ï¼šæ‰§è¡ŒGoogleæœç´¢ (æœ‰å°å¹…ä¿®æ”¹) ---
def perform_google_search(query, api_key, cse_id, num_results=3):
    url = "https://www.googleapis.com/customsearch/v1"
    params = {'key': api_key, 'cx': cse_id, 'q': query, 'num': num_results}
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        search_results = response.json()
        # ã€ä¿®æ”¹ã€‘ç°åœ¨åŒæ—¶è¿”å›æ‘˜è¦(snippet)å’Œå®Œæ•´çš„æ¥æºä¿¡æ¯(items)
        items = search_results.get('items', [])
        snippets = [item.get('snippet', '') for item in items]
        sources = [{'title': item.get('title'), 'link': item.get('link')} for item in items]
        return snippets, sources
    except requests.exceptions.RequestException as e:
        print(f"Googleæœç´¢è¯·æ±‚å¤±è´¥: {e}")
        return [], []

# --- 4. æ ¸å¿ƒAIæŒ‡ä»¤ (Prompt) (å®Œå…¨é‡å†™) ---
PROMPT_TEMPLATE = """
As 'Academic Compass', a top-tier career planning AI mentor, your task is to generate a detailed analysis report based on the provided information.
**Crucially, you must adhere to the citation rules and generate the entire response strictly in {output_language}.**

**Citation Rules (VERY IMPORTANT):**
1.  The research data provided below is structured with a unique `[Source ID: X]`.
2.  When you use information from a source, you **MUST** append its corresponding ID tag at the end of the sentence.
3.  **DO NOT GROUP CITATIONS.** Each citation must be in its own brackets. For example, to cite sources 1 and 2, you MUST write it as `[Source ID: 1][Source ID: 2]`. **NEVER write `[Source ID: 1, 2]`**.
4.  At the end of your entire report, you **MUST** include a section titled `---REFERENCES---`.
5.  Under this title, list **ONLY** the sources you actually cited. Format it as: `[Source ID: X] Title of the source`.

**Information Provided:**
1.  **User's Profile:**
    - **Major/Field of Study:** {major}
    - **Interests/Skills:** {interests}
2.  **User's Resume/Bio (if provided):**
    ```
    {resume_text}
    ```
3.  **Research Data (Search results from job sites, academic papers, articles, etc.):**
    ```
    {context_with_sources}
    ```

**Your Task:**
Synthesize all the information to create an inspiring and actionable analysis report with citations. The report MUST include the following sections IN THIS ORDER:

**1. Potential Career Path Analysis:**
Identify and describe 2-3 distinct career paths (e.g., "The Industry Researcher," "The Startup Founder," "The Academic Scholar"). For each path, analyze its core responsibilities, required skills, and industry outlook. **Cite your sources for every claim.**

**2. Salary & Job Market Insights (Canada-focused):**
Based on the research data, provide salary expectations and job market trends for the identified paths, with a focus on the Canadian market if information is available. **Cite your sources.**

**3. Personalized Match & Development Plan (if resume is provided):**
Analyze how well the applicant's background (from the resume) matches the identified career paths. Provide a brief match report and suggest 2-3 concrete steps for skill development or resume optimization. **Cite your sources.** If no resume is provided, state that this section is unavailable.

**4. Final Recommendations:**
Conclude with a summary and provide a final recommendation on which path might be the most promising, justifying your reasoning with evidence from ALL previous sections. **Cite the sources** that led to your conclusion.

**Remember to end your response with the `---REFERENCES---` section.**
"""
# --- End of Prompt ---

# --- 5. APIè·¯ç”± (å®Œå…¨é‡æ„) ---
@app.route('/analyze', methods=['POST'])
@limiter.limit("5 per day") # --- æ–°å¢ï¼šåº”ç”¨é™æµè§„åˆ™ï¼æ¯å¤©æ¯ä¸ªIP 5æ¬¡ ---
def analyze_academic_profile():
    print("--- ğŸ§­ Academic Compass v3.0 Analysis Request Received! ---")
    try:
        data = request.get_json()
        major = data.get('major')
        interests = data.get('interests', '')
        resume_text = data.get('resumeText', 'No resume provided.')
        lang_code = data.get('language', 'en')

        if not major:
            return jsonify({"error": "ä¸“ä¸š/ç ”ç©¶é¢†åŸŸæ˜¯å¿…å¡«é¡¹ã€‚"}), 400

        # ã€é‡æ„ã€‘å¼•å…¥source_mapå’Œcontext_blocksæ¥ç®¡ç†å¼•ç”¨æº
        context_blocks = []
        source_map = {}
        source_id_counter = 1

        print(f"ğŸ” Searching for: {major} in Canada...")
        
        # åŠ æ‹¿å¤§æœ¬åœ°åŒ–æœç´¢æŸ¥è¯¢
        primary_query_subject = f'"{major}"'
        if interests:
            primary_query_subject += f' AND "{interests}"'
        location_keyword = "Canada"

        search_queries = [
            f'{primary_query_subject} career paths {location_keyword}',
            f'{primary_query_subject} salary {location_keyword} site:glassdoor.ca OR site:ca.indeed.com/salaries',
            f'{primary_query_subject} jobs {location_keyword} site:ca.indeed.com OR site:linkedin.com/jobs',
            f'{primary_query_subject} skills required {location_keyword}'
        ]
        
        # ã€é‡æ„ã€‘å¤„ç†æœç´¢ç»“æœï¼Œå¹¶ä¸ºæ¯ä¸ªæ¥æºåˆ†é…IDå’Œç±»å‹
        for query in search_queries:
            snippets, sources_data = perform_google_search(query, SEARCH_API_KEY, SEARCH_ENGINE_ID, num_results=2)
            for i, snippet in enumerate(snippets):
                if i < len(sources_data):
                    source_info = sources_data[i]
                    link = source_info.get('link', '').lower()
                    
                    # åˆ¤æ–­æ¥æºç±»å‹
                    if 'linkedin.com' in link:
                        source_info['source_type'] = 'linkedin'
                    elif 'glassdoor.com' in link or 'glassdoor.ca' in link:
                        source_info['source_type'] = 'glassdoor'
                    elif 'indeed.com' in link or 'ca.indeed.com' in link:
                        source_info['source_type'] = 'indeed'
                    else:
                        source_info['source_type'] = 'default'

                    context_blocks.append(f"[Source ID: {source_id_counter}] {snippet}")
                    source_map[source_id_counter] = source_info
                    source_id_counter += 1
            time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        
        if not context_blocks:
             return jsonify({"analysis": "No information found for this major.", "sources": []})

        context_with_sources = "\n\n".join(context_blocks)
        print(f"  -> Prepared {len(context_blocks)} context blocks for AI.")

        language_instructions = {'en': 'English', 'zh-CN': 'Simplified Chinese (ç®€ä½“ä¸­æ–‡)', 'zh-TW': 'Traditional Chinese (ç¹é«”ä¸­æ–‡)'}
        output_language = language_instructions.get(lang_code, 'English')

        full_prompt = PROMPT_TEMPLATE.format(
            output_language=output_language,
            major=major,
            interests=interests or "Not provided",
            resume_text=resume_text,
            context_with_sources=context_with_sources
        )

        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        response = model.generate_content(full_prompt)
        ai_response_text = response.text
        
        print("  -> Received response from Gemini. Parsing citations...")

        # ã€é‡æ„ã€‘è§£æAIå›å¤ï¼Œåˆ†ç¦»æŠ¥å‘Šå’Œå¼•ç”¨
        analysis_part = ai_response_text
        final_sources = []

        if "---REFERENCES---" in ai_response_text:
            parts = ai_response_text.split("---REFERENCES---")
            analysis_part = parts[0].strip()
            references_part = parts[1].strip()
            
            # ä» ---REFERENCES--- éƒ¨åˆ†æå–è¢«å¼•ç”¨çš„ID
            cited_ids = re.findall(r'\[Source ID: (\d+)\]', references_part)
            
            for sid_str in cited_ids:
                sid = int(sid_str)
                if sid in source_map:
                    source_detail = source_map[sid]
                    source_detail['id'] = sid
                    final_sources.append(source_detail)
            
            # å°†æ­£æ–‡ä¸­çš„ [Source ID: X] æ›¿æ¢ä¸ºæ›´ç®€æ´çš„ [X]
            analysis_part = re.sub(r'\[Source ID: (\d+)\]', r'[\1]', analysis_part)

        print(f"  -> Successfully parsed {len(final_sources)} cited sources.")
        return jsonify({"analysis": analysis_part, "sources": final_sources})

    except Exception as e:
        print(f"!!! å‘ç”ŸæœªçŸ¥é”™è¯¯: {e} !!!")
        return jsonify({"error": "An internal server error occurred."}), 500

# --- æ–°å¢ï¼šè‡ªå®šä¹‰é™æµé”™è¯¯å¤„ç†å‡½æ•° ---
@app.errorhandler(429)
def ratelimit_handler(e):
    # è¿™æ˜¯ä¸ºä½ å®šåˆ¶çš„æç¤ºä¿¡æ¯
    error_message = (
        "åŒå­¦ï¼Œæ‚¨ä»Šæ—¥çš„å…è´¹æ¢ç´¢æ¬¡æ•°å·²ç”¨å°½ï¼ğŸ§­\n\n"
        "Academic Compass æ¯å¤©ä¸ºæ‰€æœ‰ç”¨æˆ·æä¾›5æ¬¡å…è´¹ç”Ÿæ¶¯è§„åˆ’åˆ†æã€‚\n"
        "å¦‚æœéœ€è¦æ›´å¤šæ”¯æŒï¼Œæ¬¢è¿æ˜å¤©å†æ¥æ¢ç´¢ï¼Œæˆ–é€šè¿‡â€˜è¯·æˆ‘å–æ¯å’–å•¡â˜•ï¸â€™æ¥æ”¯æŒé¡¹ç›®å‘å±•ï¼"
    )
    # è¿”å›ä¸€ä¸ªç‰¹æ®Šçš„å­—æ®µï¼Œè®©å‰ç«¯å¯ä»¥è¯†åˆ«è¿™æ˜¯é™æµé”™è¯¯
    return jsonify(error="rate_limit_exceeded", message=error_message), 429


if __name__ == '__main__':
    port = int(os.environ.get("PORT", 8080))
    app.run(host='0.0.0.0', port=port, debug=True)



